{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "def load_and_preprocess_image(url, img_size=(224, 224)):\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    img = img.resize(img_size)\n",
    "    img = np.array(img) / 255.0  # normalize to [0,1] range\n",
    "    return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv('menu_data.csv')\n",
    "\n",
    "# Load images\n",
    "images = np.array([load_and_preprocess_image(url) for url in df['img_url']])\n",
    "\n",
    "# Extract numerical price from the price string\n",
    "prices = np.array([int(re.search(r'\\d+', price).group()) for price in df['price']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=images.shape[1:])\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1)(x)  # Only one output node, because we're doing regression\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "model.compile(optimizer=Adam(), loss='mean_squared_error')  # Regression task, so we use MSE loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 109s 14s/step - loss: 166026.9531 - val_loss: 1361185.0000\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 62s 12s/step - loss: 49125.7773 - val_loss: 297498.7188\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 64s 13s/step - loss: 49345.6602 - val_loss: 136936.9062\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 62s 12s/step - loss: 27781.0312 - val_loss: 449345.0000\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 62s 12s/step - loss: 20525.7051 - val_loss: 352028.8125\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 64s 12s/step - loss: 21443.8809 - val_loss: 802425.1875\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 68s 13s/step - loss: 11151.7695 - val_loss: 632714.7500\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 79s 16s/step - loss: 10598.4443 - val_loss: 1266772.5000\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 75s 14s/step - loss: 10459.5732 - val_loss: 1207523.8750\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 62s 12s/step - loss: 8334.6367 - val_loss: 10627664.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x214808780a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(images, prices, epochs=10, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_price(model, img_url):\n",
    "    # 画像のダウンロードと前処理\n",
    "    img = load_and_preprocess_image(img_url)\n",
    "    img = np.expand_dims(img, axis=0)  # モデルに合わせて次元を追加\n",
    "\n",
    "    # 価格予測\n",
    "    predicted_price = model.predict(img)\n",
    "    \n",
    "    return predicted_price[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in c:\\users\\shota\\anaconda3\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\shota\\anaconda3\\lib\\site-packages (from optuna) (1.11.1)\n",
      "Requirement already satisfied: cmaes>=0.9.1 in c:\\users\\shota\\anaconda3\\lib\\site-packages (from optuna) (0.9.1)\n",
      "Requirement already satisfied: colorlog in c:\\users\\shota\\anaconda3\\lib\\site-packages (from optuna) (6.7.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\shota\\anaconda3\\lib\\site-packages (from optuna) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\shota\\anaconda3\\lib\\site-packages (from optuna) (23.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\shota\\anaconda3\\lib\\site-packages (from optuna) (1.4.39)\n",
      "Requirement already satisfied: tqdm in c:\\users\\shota\\anaconda3\\lib\\site-packages (from optuna) (4.65.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\shota\\anaconda3\\lib\\site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: Mako in c:\\users\\shota\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\shota\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\shota\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (6.0.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\shota\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (5.2.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\shota\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\shota\\anaconda3\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\shota\\anaconda3\\lib\\site-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\shota\\anaconda3\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'path_to_your_images_file.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Load images and prices data\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpath_to_your_images_file.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m prices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath_to_your_prices_file.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Now, you can use images and prices in your optimization\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    403\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 405\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    406\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path_to_your_images_file.npy'"
     ]
    }
   ],
   "source": [
    "!pip install optuna\n",
    "\n",
    "import optuna\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "def create_model(trial, input_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    # 畳み込み層\n",
    "    model.add(Conv2D(filters=trial.suggest_int(\"filters\", 32, 128), kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "    # 全結合層\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=trial.suggest_int(\"units\", 32, 128), activation='relu'))\n",
    "\n",
    "    # 出力層\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    return model\n",
    "\n",
    "def objective(trial, X, y):\n",
    "    model = create_model(trial, X.shape[1:])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    history = model.fit(X, y, epochs=5, validation_split=0.2, batch_size=32, verbose=0)\n",
    "\n",
    "    return history.history[\"val_loss\"][-1]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Load images and prices data\n",
    "images = np.load('path_to_your_images_file.npy')\n",
    "prices = np.load('path_to_your_prices_file.npy')\n",
    "\n",
    "# Now, you can use images and prices in your optimization\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(lambda trial: objective(trial, images, prices), n_trials=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 143ms/step\n",
      "Predicted price:  3497.5671\n"
     ]
    }
   ],
   "source": [
    "new_img_url = \"https://img.pretty-online.jp/wp-content/uploads/2022/07/21140818/gourmet_shinosakalunch_3.jpeg.webp\"  # 予測したい画像のURL\n",
    "predicted_price = predict_price(model, new_img_url)\n",
    "\n",
    "print(\"Predicted price: \", predicted_price)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
